---
title: "da410_project3"
author: "Jason Grahn"
date: "1/27/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library(tidyverse)
library(MASS)
```

#Problem 1.

## 1. Use admission.csv as a training dataset.

We're going to use `admission.csv` twice, so importing once and calling it good.
```{r import admission csv}
admission <- readr::read_csv(here::here("project3/admission.csv"), 
                             col_types = cols(De = col_factor(levels = c("admit", "border", "notadmit"))))

#plot scatter to look for clustering
admission %>% 
  ggplot(aes(x = GPA, y = GMAT, color = De)) +
  geom_point() +
  theme_classic() +
  theme(legend.position = "bottom")
```

## 2. Train model using LDA by setting admit/not-admit/border with the same probabilities.
```{r build the lda model}
model_1 <- lda(formula = De ~ ., 
                        data = admission, 
                        prior = c(1,1,1)/3)

model_1
```

## 3. Calculate the misclassfication rate
```{r}
#apply the model to admissions with predict()
predict_admit <- predict(model_1, # predictions
                data = admissions)

#pull the predictions and
predict_class <- predict_admit$class

#I might want to use that data later, so let's write them back to the table
admission_predictions <- admission %>% 
  mutate(predictions = predict_admit$class,
         LD1 = predict_admit$x[,1],
         LD2 = predict_admit$x[,2])

#back to misclassification
#quick glance of predictions versus actuals
table(predict_class, admission$De)

admission_predictions %>% 
  mutate(correct_class = factor((De == predictions))) %>% 
  group_by(correct_class) %>% 
  summarise(classified_count = n(), 
            total = nrow(admission_predictions)) %>% 
  mutate(percentage = round(classified_count / total * 100, 2)) 
```

## 4. Predict students with GPA and SAT score as below.
```{r build a dataframe of the students to predict}
GPA <- c(3.14, 3.08, 2.08, 3.22)
GMAT <- c(470, 591, 641, 463)
p_student <- as.factor(c("student1", "student2", "student3", "student4"))

predict_me <- tibble(p_student, p_gpa, p_gmat)
predict_me

predict_subgroup <- predict(model_1, # predictions
                            newdata = predict_me)
```


# Problem 2.

## 1. Use admission.csv as a training dataset.

## 2. Train model using LDA by setting probability of admit is 50% while probability of not admit is 25% and probability of border is 25%.

## 3. Calculate the misclassfication rate

## 4. Predict students with GPA and SAT score as below.
3.14 	470
3.08 	591
2.08 	641
3.22 	463

## Compare differences of the result from problem1.

# Problem 3.

## Explain what is Quadratic Discriminant Analysis (QDA), and use QDA to train the model, discuss if this project can be done better by QDA, why or why not. 