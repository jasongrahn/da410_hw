---
title: "midterm"
author: "Jason Grahn"
date: "2/9/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, include = FALSE)
library(tidyverse)
library(class)
library(MASS)
```

# 4 
In the following table, we have a comparison of four reagents. The first reagent is the one presently in use and the other three are less expensive reagents that we wish to compare with the first. All four reagents are used with a blood sample from each patient.

The three variables measured for each reagent are 𝑦1=white blood count, 𝑦2=red blood count, and 𝑦3=hemoglobin count. Compare the four reagents using all four MANOVA tests. State each hypotheses clearly, and interpret the results.
```{r import reagent, message=FALSE, warning=FALSE}
reagent <- readr::read_table2(file = here::here("/midterm/T6_19_REAGENT.DAT"),
                   col_names = FALSE) %>% 
  rename(reagent = X1,
         subject = X2,
         y1 = X3,
         y2 = X4,
         y3 = X5) %>% 
  mutate(reagent = factor(reagent),
         subject = factor(subject))

head(reagent,5)
```

```{r build manova}
manova.reagent <- manova(cbind(y1, y2, y3) ~ reagent,
                         data=reagent)

manova.reagent
```

## The Hypothesis 
> $H_0$: The mean vectors between reagents are equal ( $\mu_o = \mu_1$).

> $H_a$: The mean vectors between reagents are not equal ( $\mu_o \neq \mu_1$). 

## The tests

```{r}
reagent.lambda <- broom::tidy(manova.reagent, test = "Wilks")
reagent.lambda
```

### Wilks interpretation
p-Value of reagent.lambda is `r reagent.lambda$p.value[1]`. This value is above 0.05; so we do not reject $H_0$ and conclude that the means are equal. 

```{r}
reagent.pillai <- broom::tidy(manova.reagent, test = "Pillai")
reagent.pillai
```

### Pillai interpretation
p-Value of reagent.pillai is `r reagent.pillai$p.value[1]`. This value is above 0.05; so we do not reject $H_0$ and conclude that the means are equal. 

```{r}
reagent.hotel <- broom::tidy(manova.reagent, test = "Hotelling-Lawley")
reagent.hotel
```

### Hotelling interpretation

p-Value of reagent.hotel is `r reagent.hotel$p.value[1]`. This value is above 0.05; so we do not reject $H_0$ and conclude that the means are equal. 

```{r}
reagent.roy <- broom::tidy(manova.reagent, test = "Roy",
                           intercept = FALSE)

reagent.roy

roy.theta <- round(reagent.roy$roy[1]/(reagent.roy$roy[1] + 1), 3)
roy.theta
```

### Roy interpretation

p-Value of reagent.roy is `r reagent.roy$p.value[1]`. While this value is below 0.05; Roy's Theta is `r roy.theta` so we do not reject $H_0$ and conclude that the means are equal. 

#5 
The table below displays scores on math, English, and art tests for 5 students. Note that data from the table is represented in matrix A, where each column in the matrix shows scores on a test and each row shows scores for a student:

```{r import student}
#input data
student <- as.factor(c(1, 2, 3, 4, 5))
math    <- c(90,90,60,60,30) 
english <- c(60,90,60,60,30)
art     <- c(90,30,60,90,30)

#make a table
students <- tibble(student, math, english, art)
#students
```

## (a) Calculate the sample covariance matrix S
```{r}
S <- round(var(students %>% 
                 select(math, english, art))
           , 2)
S
```

## (b) Calculate the sample correlation matrix R.
```{r}
R <- round(cor(S), 2)
R
```

## (c) Now let’s define 𝑧 = −2𝑦1 + 3𝑦2 + 𝑦3,where 𝑦1denotes Math scores, 𝑦2 denotes English scores, and 𝑦3 denotes Art scores. Find the sample mean vector 𝑧 and the sample variance 𝑠2.
```{r}
#build the constant matrix
a <- matrix(c(-2, 3, 1))

#gather the column means
y <- colMeans(students %>% select(2:4))

#sample mean vector
z <- y %*% t(a)
z

#sample variance
s2 <- t(a) %*% as.matrix(S) %*% a
s2
```

#6 
Use the beetle data, do the following:
```{r import beetle}
beetles <- readr::read_table2(file = here::here("/midterm/T5_5_FBEETLES.DAT"),
                   col_names = FALSE) %>% 
  rename(exp.no = X1,
         species = X2,
         y1 = X3,
         y2 = X4,
         y3 = X5,
         y4 = X6) %>% 
  select(y1, y2, y3, y4, species) %>% 
  mutate(species = factor(species))

head(beetles,5)
```

## (a) Find the classification function and cutoff point.
```{r}
# group by species
beet1 <- subset(x = beetles, subset = (species == 1), y1:y4)
beet2 <- subset(x = beetles, subset = (species == 2), y1:y4)
# find group means for all variables for each species
mean1 <- apply(X = beet1, FUN = mean, MARGIN = 2)
#mean1
mean2 <- apply(X = beet2, FUN = mean, MARGIN = 2)
#mean2
# find covariance matrix for each species
var1 <- var(beet1)
#var1
var2 <- var(beet2)
#var2

beetles.manova <- stats::manova(cbind(y1, y2, y3, y4) ~ species, 
                                data = beetles)

# find _pooled_ sample variance for each species
## length of each set
length1 <- nrow(beet1)
length2 <- nrow(beet2)
## variance of each set
pvar1 <- (length1 - 1) * var1
pvar2 <- (length2 - 1) * var2 
## use length and variance to get pooled variance
sp1 <- 1 / (length1 + length2 - 2) * (pvar1 + pvar2)
#sp1

cutoff <- .5*(mean1 - mean2) %*% solve(sp1) %*% (mean1 + mean2)
cutoff <- round(cutoff,2)
cutoff
```

```{r}
species_prediction <- apply(beetles[,1:4], 1, function(y) {
 z <- (mean1 - mean2) %*% solve(sp1) %*% y })
species_prediction
```

## (b) Find the classification table using the nearest neighbor method by setting k = 3.
```{r Building KNearest Neighbor}
## Normalization
normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x))) }

normalized.beetles <- as.data.frame(lapply(beetles[1:4], normalize))

## Splitting Data Set into Training and Test Sets
## r subset datasets
set.seed(1234)
ind <- sample(2, 
              nrow(beetles), 
              replace=TRUE, 
              prob=c(0.67, 0.33))

# make training set and labels
beetles.training <- beetles[ind==1, 1:4]
beetles.trainLabels <- as.matrix(beetles[ind==1, 5])

# make testing set and labels
beetles.test <- beetles[ind==2, 1:4]
beetles.testLabels <- as.matrix(beetles[ind==2, 5])
```

### K-Nearest Neighbor in R
```{r knn the beetles}
beetles.knn <- knn(train = beetles.training,
                   cl = beetles.trainLabels,
                   k = 3,
                   test = beetles.test)

table(beetles.knn)
```

## (c) Calculate misclassification rate.
```{r misclassification rate}
table(beetles.testLabels, beetles.knn)

accuracy.table <- beetles %>% 
  mutate(ind = ind) %>% 
  filter(ind == 2) %>% 
  mutate(beetles.knn = beetles.knn,
         predict.true = if_else(species == beetles.knn, TRUE, FALSE)) 

accuracy.rate <- accuracy.table %>% 
  group_by(predict.true) %>% 
  summarize(count = n(),
            rate = count / nrow(accuracy.table) * 100,
            rate = round(rate,2))

accuracy.rate
```

#7
Use the above beetle data, do the following:
## (a) Use LDA by setting probability of 50% and 50% to train model.
```{r}
model_1 <- lda(formula = species ~ ., 
                        data = beetles, 
                        prior = c(1,1)/2)
model_1
```

## (b) Predict new observation (189,245,138,164).
```{r}
y1 <- 189 
y2 <- 245 
y3 <- 138
y4 <- 164
predict_me <- tibble(y1, y2, y3, y4)

predict_subgroup <- predict(model_1, # predictions
                            newdata = predict_me)

predict_subgroup$class
```

The LDA method predicts the new observation will be beetle species 1, which is _Haltica oleracea_. 

## (c) Calculate misclassification rate.
```{r}
predict_beetles <- predict(model_1, # predictions
                           data = beetles)

predict_class <- predict_beetles$class

beetle_predictions <- beetles %>% 
  mutate(predictions = predict_class,
         correct_species = factor((species == predictions))) %>% 
  group_by(correct_species) %>% 
  summarise(classified_count = n(), 
            total = nrow(beetles)) %>% 
  mutate(percentage = round(classified_count / total * 100, 2)) 

beetle_predictions
```

It's not clear if this question is asking about LDA for the overall beetle prediction or just the new observation. Assuming this question is asking about the overall beetle population, the misclassification rate is `r beetle_predictions$percentage[1]` %. 

# 8
The following table contains data from O’Sullivan and Mahan with measurements of blood glucose levels on three occasions for 30 women. The 𝑦’s represent fasting glucose measurements on the three occasions; the 𝑥’s are glucose measurements 1 hour after sugar intake.

```{r import glucose}
glucose <- read_csv(here::here("midterm/glucose.csv"))

head(glucose, 5)
```

## Find the mean vector 
```{r mean vector}
glucose_means <- matrix(colMeans(glucose))
glucose_means
```

## ... and covariance matrix for all six variables 
```{r covariance matrix}
S_glucose <- round(var(glucose), 2)
S_glucose
```

# 9 
Various aspects of economic cycles were measured for consumer goods and producer goods by Tintner. The variables are: 

    𝑦1=length of cycle
    𝑦2=percentage of rising prices
    𝑦3=cyclical amplitude
    𝑦4=rate of change

The data for several items are given in the following table:
```{r import goods}
goods <- readr::read_table2(file = here::here("/midterm/T5_8_GOODS.DAT"),
                   col_names = FALSE) %>% 
  rename(item = X1,
         goods_type = X2,
         y1 = X3,
         y2 = X4,
         y3 = X5,
         y4 = X6) %>% 
  mutate(item = factor(item),
         goods_type = factor(goods_type))

head(goods,5)
```

## Use Hotelling’s $T^2$ test to test for a difference in the mean measurements vector of the Consumers Goods and the mean vector of the Producer Goods. State each hypotheses clearly, and interpret the results.

###  The Hypothesis 
> $H_0$: The mean vectors between good types are equal ( $\mu_o = \mu_1$).

> $H_a$: The mean vectors between good types are not equal ( $\mu_o \neq \mu_1$). 

```{r build goods manova}
manova.goods <- manova(cbind(y1, y2, y3, y4) ~ goods_type,
                       data=goods)

manova.goods
```

### The Test
```{r apply hotelling test to goods manova}
goods.hotel <- broom::tidy(manova.goods, test = "Hotelling-Lawley")
goods.hotel
```

### The Interpretation

p-Value of reagent.hotel is `r round(goods.hotel$p.value[1],3)`. This value is above 0.05; so we reject $H_0$ and conclude that the means vectors are _not_ equal between consumer and producer goods. 