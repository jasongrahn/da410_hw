---
title: "da_410_project2_grahn"
author: "Jason Grahn"
date: "1/14/2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = TRUE, warning = TRUE)
library(tidyverse)
library(dendextend)

```

##Download airpoll.txt. In this problem, we will only focus on the first 16 observations (cities). Read the data into R (as a data frame) and name the data as airpol.full. Then use the following code to “extract” the first 16 observations.
```{r}
#import the dataset dataset as a better table.
airpol.full <- read.csv("airpoll.txt", header = TRUE, sep = " ")

#This is old bad code.
#airpol.full <- read.table("http://www.stat.sc.edu/~hitchcock/airpoll.txt", header=T)

#extract the first 16 observations
airpol.data.sub <- head(airpol.full, 16)
```

##Display the subset data airpol.data.sub
```{r}
#show that table
airpol.data.sub
airpol.data.num.sub <- airpol.data.sub %>% select(Rainfall:Mortality)
```

##Use R to perform the following analysis on the subset data airpol.data.sub. Make sure you include clear headings, command lines, and relevant output/results.

###a) Calculate the sample covariance matrix and the sample correlation matrix. 
```{r}
#sample covariance matrix
S <- round(var(airpol.data.num.sub), 2)
S

#sample correlation matrix
R <- round(cor(airpol.data.num.sub), 2)
R

#Identify which pairs of variables seem to be strongly associated
#and describe the nature (strength and direction) of the relationship between these variable pairs.
library(ggcorrplot)
ggcorrplot(R, 
           type = "lower",
           title = "correlation matrix of airpol.data.",
           show.legend = TRUE,
           digits = 2,
           lab = TRUE)
```

From the plot we can see NOX and SO2 have the strongest correlation of the data, headed positive. the most negative is Education and Mortality. SO2 and Popden is also a semi-strong positive relationship. Everything else sits in a sort-of weak relationship.

###(b) Calculate the distance matrix for these observations (after scaling the variables by dividing each variable by its standard deviation). 
```{r}
#find standard deviation for variables
std <- sapply(airpol.data.num.sub, sd)  

#divide each variable by its std to normalize the data
airpol.data.sub.std <- sweep(x = airpol.data.num.sub, #sweep the airpol data
                             MARGIN = 2, #dunno what the MARGIN 
                             STATS = std, #using the standard deviation
                             FUN = "/") #by division 

#find the distance matrix for the dataframe using all the default options
dis <- dist(airpol.data.sub.std)

dist2full <- function(ds) { 
  n <- attr(ds,"Size") 
  full <- matrix(0,n,n) 
  full[lower.tri(full)] <- ds 
  full + t(full) 
  } 

dis.matrix <- round(dist2full(dis), 2)
dis.matrix
```

##Describe some of the most similar pairs of cities and some of the most different pairs of cities, giving evidence from the distance matrix.
```{r}
#convert dis to a matrix
dist_m <- as.matrix(dis)

# Create a dendrogram and plot it
dend <- dist_m %>%  scale %>% 
        dist %>% hclust %>% as.dendrogram

ggd1 <- as.ggdend(dend %>% 
                    set("labels", c(" dallas TX", " atlant GA", " allen PA", " bridge CT", " boston MA",
                                    " clevel OH", " akron OH"," colomb OH", " albany NY", " canton OH", 
                                    " bufalo NY", " cinnci OH", " birmhm AL", " chatag TN", " baltim MD", " chicag IL")) %>% 
                    set("labels_cex", .6)
                  ) 

ggplot(ggd1, 
       horiz = TRUE, 
       theme =  theme_minimal()) +
  labs(title = "Distance matrix, visualized",
       subtitle = "shows Columbus and Akron OH are closest, 
       while Chicago and Dallas furthest apart",
       x = "",
       y = "scaled Euclidian distance")
```

###(c) Display a plot that will help assess whether this data set comes from a multivariate normal distribution. What is your conclusion based on the plot?
```{r}
#Copy the chisplot function into R 
chisplot <- function(x) { 
  if (!is.matrix(x)) stop("x is not a matrix") 
  ### determine dimensions 
  n <- nrow(x) 
  p <- ncol(x) 
  xbar <- apply(x, 2, mean) 
  S <- var(x) 
  S <- solve(S) 
  index <- (1:n)/(n+1)
  xcent <- t(t(x) - xbar) 
  di <- apply(xcent, 1, function(x,S) x %*% S %*% x,S) 
  quant <- qchisq(index,p) 
  plot(quant, sort(di), 
       ylab = "Ordered distances", 
       xlab = "Chi-square quantile", 
       lwd=2,
       pch=1)
  }

chisplot(as.matrix(airpol.data.num.sub))

#better, and without the need of the chisplot function:
library(RVAideMemoire)
mqqnorm(as.matrix(airpol.data.num.sub))
```

